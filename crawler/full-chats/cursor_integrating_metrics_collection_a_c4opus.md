# Integrating metrics collection and visualization
_Exported on 6/10/2025 at 23:25:48 PDT from Cursor (0.50.5)_

---

**User**

Can you help me add proper metrics collection and visualization to my web crawler? Currently metrics are just logged periodically in CrawlerOrchestrator._log_metrics. After each run of the crawler I then need to filter and parse the logs. Ideally I would be able to have something like a rudimentary DataDog where I can visualize metrics as they appear in real-time, correlate different metrics, and maybe do some basic aggregations such as smoothing or averaging. I heard some people use Grafana/Prometheus but I'm not sure what exactly those libraries do, how to use them to make dashboards, or integrate them into my application. Open to suggestions too. Let's discuss before coding

---

**Cursor**

Great question! Let me explain the monitoring stack options and help you choose the best approach for your web crawler.

## Understanding Prometheus & Grafana

**Prometheus** is a time-series database and monitoring system that:
- Collects metrics by "scraping" HTTP endpoints at regular intervals
- Stores metrics with timestamps in its efficient time-series database
- Provides a powerful query language (PromQL) for aggregations and calculations
- Is designed for reliability and can run on a single machine

**Grafana** is a visualization platform that:
- Connects to data sources like Prometheus
- Creates interactive dashboards with various chart types
- Updates in real-time as new data arrives
- Allows you to correlate multiple metrics on the same graph

## How They Work Together

1. Your crawler exposes metrics on an HTTP endpoint (e.g., `http://localhost:8000/metrics`)
2. Prometheus scrapes this endpoint every 15-30 seconds
3. Grafana queries Prometheus and visualizes the data in dashboards

## Recommended Approach for Your Crawler

For your use case, I'd recommend the Prometheus + Grafana stack because:
- It's free and open-source
- Runs well on a single machine
- Perfect for the metrics you want to track
- Has excellent Python integration via `prometheus_client`

## Metrics to Track

Looking at your current `_log_metrics` method, here are the metrics I'd suggest implementing:

**Counters** (always increasing):
- `crawler_pages_crawled_total` - Total pages crawled
- `crawler_urls_added_total` - Total URLs added to frontier
- `crawler_errors_total` - Errors by type (network, parsing, etc.)

**Gauges** (can go up or down):
- `crawler_pages_per_second` - Current crawl rate
- `crawler_frontier_size` - Current frontier size
- `crawler_active_workers` - Number of active workers
- `crawler_memory_usage_bytes` - RSS memory
- `crawler_open_fds` - Open file descriptors
- `crawler_db_pool_available` - Available DB connections

**Histograms** (measure distributions):
- `crawler_fetch_duration_seconds` - Time to fetch URLs
- `crawler_db_connection_acquire_seconds` - DB connection acquire time
- `crawler_db_query_duration_seconds` - DB query execution time

## Implementation Options

### Option 1: Docker Compose (Easiest Setup)
I can provide a `docker-compose.yml` that sets up Prometheus and Grafana with one command. Your crawler would just need to expose metrics.

### Option 2: Manual Installation
Install Prometheus and Grafana directly on your system and configure them.

### Option 3: Lightweight Alternative
If you want something simpler, we could use:
- **InfluxDB** (time-series DB) + **Grafana**
- Or even a simple Flask dashboard with **Plotly** for real-time charts

## Next Steps

Would you like me to:

1. **Set up the full Prometheus + Grafana stack** with Docker Compose for easy deployment?
2. **Instrument your crawler code** with `prometheus_client` to expose all the metrics?
3. **Create a pre-configured Grafana dashboard** specifically for your crawler metrics?
4. **Start with a simpler solution** like a basic web dashboard?

The Prometheus + Grafana approach would give you exactly what you described - real-time visualization, metric correlation, and aggregations like smoothing and averaging. It's what most production systems use and would be a valuable skill to learn.

What's your preference? Would you like to go with the industry-standard Prometheus + Grafana setup, or would you prefer to explore a lighter-weight alternative first?

---

**User**

Yeah let's setup the prometheus + grafana stack with docker compose?

Try to keep things simple so the code can be easily maintained and the run instructions are easy to follow please

Also please update README.MD and PLAN.MD where relevant

---

**Cursor**

Perfect! Let's set up a simple Prometheus + Grafana monitoring stack for your crawler. I'll keep it straightforward and easy to maintain.

Here's what we'll do:
1. Create a Docker Compose setup for Prometheus and Grafana
2. Add metrics collection to your crawler using `prometheus_client`
3. Create a basic Grafana dashboard
4. Update the documentation

Let me start by creating the necessary files:

```dockercompose
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    container_name: crawler_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
    restart: unless-stopped
    extra_hosts:
      - "host.docker.internal:host-gateway"  # Allows access to host machine

  grafana:
    image: grafana/grafana:latest
    container_name: crawler_grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    restart: unless-stopped

volumes:
  prometheus_data:
  grafana_data:
```

```yaml
global:
  scrape_interval: 15s  # How often to scrape metrics
  evaluation_interval: 15s  # How often to evaluate rules

scrape_configs:
  - job_name: 'crawler'
    static_configs:
      - targets: ['host.docker.internal:8001']  # Crawler metrics endpoint
        labels:
          instance: 'main-crawler'
```

```yaml
apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: true
```

```yaml
apiVersion: 1

providers:
  - name: 'default'
    orgId: 1
    folder: ''
    type: file
    disableDeletion: false
    updateIntervalSeconds: 10
    options:
      path: /etc/grafana/provisioning/dashboards
```

```pip-requirements
aiohttp
lxml[html_clean]
robotexclusionrulesparser
aiofiles
cchardet==2.2.0a2
tldextract
psutil
prometheus_client
pytest
pytest-asyncio
httpx

# Optional dependencies for PostgreSQL support
# Uncomment the following line to install PostgreSQL driver:
psycopg[binary,pool]>=3.1
```

```python
"""Metrics collection for the web crawler using Prometheus."""

import asyncio
import logging
from typing import Optional
from prometheus_client import Counter, Gauge, Histogram, start_http_server
from prometheus_client.core import CollectorRegistry

logger = logging.getLogger(__name__)

# Create a custom registry to avoid conflicts
REGISTRY = CollectorRegistry()

# Counters (always increasing)
pages_crawled_counter = Counter(
    'crawler_pages_crawled_total',
    'Total number of pages successfully crawled',
    registry=REGISTRY
)

urls_added_counter = Counter(
    'crawler_urls_added_total',
    'Total number of URLs added to frontier',
    registry=REGISTRY
)

errors_counter = Counter(
    'crawler_errors_total',
    'Total number of errors by type',
    ['error_type'],  # Labels: fetch_error, parse_error, db_error, etc.
    registry=REGISTRY
)

# Gauges (can go up or down)
pages_per_second_gauge = Gauge(
    'crawler_pages_per_second',
    'Current crawl rate in pages per second',
    registry=REGISTRY
)

frontier_size_gauge = Gauge(
    'crawler_frontier_size',
    'Current size of the URL frontier',
    registry=REGISTRY
)

active_workers_gauge = Gauge(
    'crawler_active_workers',
    'Number of currently active worker tasks',
    registry=REGISTRY
)

memory_usage_gauge = Gauge(
    'crawler_memory_usage_bytes',
    'Current RSS memory usage in bytes',
    registry=REGISTRY
)

open_fds_gauge = Gauge(
    'crawler_open_fds',
    'Number of open file descriptors',
    registry=REGISTRY
)

db_pool_available_gauge = Gauge(
    'crawler_db_pool_available',
    'Number of available database connections in pool',
    registry=REGISTRY
)

# Histograms (measure distributions)
fetch_duration_histogram = Histogram(
    'crawler_fetch_duration_seconds',
    'Time taken to fetch a URL',
    buckets=(0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0),
    registry=REGISTRY
)

db_connection_acquire_histogram = Histogram(
    'crawler_db_connection_acquire_seconds',
    'Time taken to acquire a database connection',
    buckets=(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0),
    registry=REGISTRY
)

db_query_duration_histogram = Histogram(
    'crawler_db_query_duration_seconds',
    'Time taken to execute database queries',
    ['query_name'],  # Label for different query types
    buckets=(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0),
    registry=REGISTRY
)

class MetricsServer:
    """Manages the Prometheus metrics HTTP server."""
    
    def __init__(self, port: int = 8001):
        self.port = port
        self._server_started = False
    
    def start(self):
        """Start the metrics HTTP server."""
        if not self._server_started:
            try:
                start_http_server(self.port, registry=REGISTRY)
                self._server_started = True
                logger.info(f"Metrics server started on port {self.port}")
            except Exception as e:
                logger.error(f"Failed to start metrics server: {e}")
                raise
    
    def is_running(self) -> bool:
        """Check if the metrics server is running."""
        return self._server_started

# Global metrics server instance
metrics_server = MetricsServer()

def start_metrics_server(port: int = 8001):
    """Start the Prometheus metrics HTTP server."""
    metrics_server.port = port
    metrics_server.start()
```

Now let's modify the orchestrator to use these metrics:

```python
import asyncio
import logging
import time
from pathlib import Path
from typing import Set, Optional, Dict, List
import os # For process ID
import psutil
import random
from collections import defaultdict

from .config import CrawlerConfig
from .storage import StorageManager
from .fetcher import Fetcher, FetchResult
from .politeness import PolitenessEnforcer
from .frontier import FrontierManager
from .parser import PageParser, ParseResult
from .utils import extract_domain # For getting domain for storage
from .db_backends import create_backend, PostgreSQLBackend
from .metrics_utils import calculate_percentiles
from .metrics import (
    start_metrics_server,
    pages_crawled_counter,
    urls_added_counter,
    errors_counter,
    pages_per_second_gauge,
    frontier_size_gauge,
    active_workers_gauge,
    memory_usage_gauge,
    open_fds_gauge,
    db_pool_available_gauge,
    fetch_duration_histogram,
    db_connection_acquire_histogram,
    db_query_duration_histogram
)

logger = logging.getLogger(__name__)
```

Now let's update the `_log_metrics` method to also update Prometheus metrics:

```python
    async def _log_metrics(self):
        current_time = time.time()
        time_elapsed_seconds = current_time - self.last_metrics_log_time
        if time_elapsed_seconds == 0: time_elapsed_seconds = 1 # Avoid division by zero

        pages_per_second = self.pages_crawled_in_interval / time_elapsed_seconds
        logger.info(f"[Metrics] Pages Crawled/sec: {pages_per_second:.2f}")
        
        # Update Prometheus gauge
        pages_per_second_gauge.set(pages_per_second)

        # Ensure db_backend is PostgreSQLBackend for these specific metrics lists
        if isinstance(self.db_backend, PostgreSQLBackend): # type: ignore
            # Connection Acquire Times
            acquire_times = list(self.db_backend.connection_acquire_times) # Copy for processing
            self.db_backend.connection_acquire_times.clear()
            if acquire_times:
                p50_acquire = calculate_percentiles(acquire_times, [50])[0]
                p95_acquire = calculate_percentiles(acquire_times, [95])[0]
                logger.info(f"[Metrics] DB Conn Acquire Time (ms): P50={p50_acquire*1000:.2f}, P95={p95_acquire*1000:.2f} (from {len(acquire_times)} samples)")
                
                # Update Prometheus histogram with acquire times
                for acquire_time in acquire_times:
                    db_connection_acquire_histogram.observe(acquire_time)
            else:
                logger.info("[Metrics] DB Conn Acquire Time (ms): No samples")

            # Query Hold Times (for specific queries)
            query_hold_times_copy: Dict[str, List[float]] = defaultdict(list)
            for name, times in self.db_backend.query_hold_times.items():
                query_hold_times_copy[name] = list(times)
                times.clear() # Clear original list
            
            for query_name, hold_times in query_hold_times_copy.items():
                if hold_times:
                    p50_hold = calculate_percentiles(hold_times, [50])[0]
                    p95_hold = calculate_percentiles(hold_times, [95])[0]
                    max_hold = max(hold_times)
                    logger.info(f"[Metrics] Query Hold Time '{query_name}' (ms): P50={p50_hold*1000:.2f}, P95={p95_hold*1000:.2f}, MAX={max_hold*1000:.2f} (from {len(hold_times)} samples)")
                    
                    # Update Prometheus histogram with query times
                    for hold_time in hold_times:
                        db_query_duration_histogram.labels(query_name=query_name).observe(hold_time)
                # else: logger.info(f"[Metrics] Query Hold Time '{query_name}' (ms): No samples") # Optional: log if no samples

        # Reset for next interval
        self.pages_crawled_in_interval = 0
        self.last_metrics_log_time = current_time
```

Now let's update the worker method to track fetch durations and update counters:

```python
                url_to_crawl, domain, frontier_id, depth = next_url_info
                logger.info(f"Worker-{worker_id}: Processing URL ID {frontier_id} at depth {depth}: {url_to_crawl} from domain {domain}")

                # Track fetch duration
                fetch_start_time = time.time()
                fetch_result: FetchResult = await self.fetcher.fetch_url(url_to_crawl)
                fetch_duration = time.time() - fetch_start_time
                fetch_duration_histogram.observe(fetch_duration)
                
                crawled_timestamp = int(time.time())

                if fetch_result.error_message or fetch_result.status_code >= 400:
                    logger.warning(f"Worker-{worker_id}: Fetch failed for {url_to_crawl}. Status: {fetch_result.status_code}, Error: {fetch_result.error_message}")
                    
                    # Track error in Prometheus
                    if fetch_result.error_message:
                        errors_counter.labels(error_type='fetch_error').inc()
                    else:
                        errors_counter.labels(error_type=f'http_{fetch_result.status_code}').inc()
                    
                    # Record failed attempt
                    await self.storage.add_visited_page(
                        url=fetch_result.final_url, 
                        domain=extract_domain(fetch_result.final_url) or domain, # Use original domain as fallback
                        status_code=fetch_result.status_code,
                        crawled_timestamp=crawled_timestamp,
                        content_type=fetch_result.content_type,
                        redirected_to_url=fetch_result.final_url if fetch_result.is_redirect and fetch_result.initial_url != fetch_result.final_url else None
                    )
                else: # Successful fetch (2xx or 3xx that was followed)
                    self.pages_crawled_count += 1
                    pages_crawled_counter.inc()  # Increment Prometheus counter
                    logger.info(f"Worker-{worker_id}: Successfully fetched {fetch_result.final_url} (Status: {fetch_result.status_code}). Total crawled: {self.pages_crawled_count}")
```

Now let's update the part where URLs are added to track them in Prometheus:

```python
                            links_added_this_page = await self.frontier.add_urls_batch(list(parse_data.extracted_links), depth=depth + 1)
                            if links_added_this_page > 0:
                                self.total_urls_added_to_frontier += links_added_this_page
                                urls_added_counter.inc(links_added_this_page)  # Increment Prometheus counter
                                logger.info(f"Worker-{worker_id}: Added {links_added_this_page} new URLs to frontier from {fetch_result.final_url}. Total added: {self.total_urls_added_to_frontier}")
```

Now let's update the `run_crawl` method to start the metrics server and update gauge metrics:

```python
        try:
            # Initialize components that need async setup
            await self._initialize_components()
            
            # Start Prometheus metrics server
            start_metrics_server(port=8001)
            logger.info("Prometheus metrics server started on port 8001")
```

Now let's update the monitoring loop to set Prometheus gauge values:

```python
                # Use the fast, estimated count for logging
                estimated_frontier_size = await self.frontier.count_frontier()
                active_workers = sum(1 for task in self.worker_tasks if not task.done())
                
                # Update Prometheus gauges
                frontier_size_gauge.set(estimated_frontier_size)
                active_workers_gauge.set(active_workers)
                
                # Resource monitoring
                rss_mem_mb = "N/A"
                rss_mem_bytes = 0
                fds_count = "N/A"
                fds_count_int = 0
                if current_process:
                    try:
                        rss_mem_bytes = current_process.memory_info().rss
                        rss_mem_mb = f"{rss_mem_bytes / (1024 * 1024):.2f} MB"
                        fds_count_int = current_process.num_fds()
                        fds_count = fds_count_int
                        
                        # Update Prometheus gauges
                        memory_usage_gauge.set(rss_mem_bytes)
                        open_fds_gauge.set(fds_count_int)
                    except psutil.Error as e:
                        logger.warning(f"psutil error during resource monitoring: {e}")
                        # Fallback or disable further psutil calls for this iteration if needed
                
                # Connection pool info - different for each backend
                pool_info = "N/A"
                if self.config.db_type == 'sqlite' and hasattr(self.db_backend, '_pool'):
                    pool_info = f"available={self.db_backend._pool.qsize()}"
                    db_pool_available_gauge.set(self.db_backend._pool.qsize())
                elif self.config.db_type == 'postgresql':
                    pool_info = f"min={self.db_backend.min_size},max={self.db_backend.max_size}"
                    # For PostgreSQL, we'd need to expose pool stats from the backend
                    # This is a simplified version - actual implementation would query the pool
```

Now let's create a pre-configured Grafana dashboard for the crawler:

```json
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": "-- Grafana --",
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "gnetId": null,
  "graphTooltip": 0,
  "id": null,
  "links": [],
  "panels": [
    {
      "datasource": "Prometheus",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 10,
            "gradientMode": "none",
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": true,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 0
      },
      "id": 1,
      "options": {
        "tooltip": {
          "mode": "single"
        },
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom"
        }
      },
      "pluginVersion": "8.0.0",
      "targets": [
        {
          "expr": "rate(crawler_pages_crawled_total[1m]) * 60",
          "legendFormat": "Pages per minute",
          "refId": "A"
        }
      ],
      "title": "Crawl Rate",
      "type": "timeseries"
    },
    {
      "datasource": "Prometheus",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 6,
        "x": 12,
        "y": 0
      },
      "id": 2,
      "options": {
        "orientation": "auto",
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ],
          "fields": ""
        },
        "showThresholdLabels": false,
        "showThresholdMarkers": true,
        "text": {}
      },
      "pluginVersion": "8.0.0",
      "targets": [
        {
          "expr": "crawler_pages_crawled_total",
          "refId": "A"
        }
      ],
      "title": "Total Pages Crawled",
      "type": "gauge"
    },
    {
      "datasource": "Prometheus",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 10000
              },
              {
                "color": "red",
                "value": 50000
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 6,
        "x": 18,
        "y": 0
      },
      "id": 3,
      "options": {
        "orientation": "auto",
        "reduceOptions": {
          "values": false,
          "calcs": [
            "lastNotNull"
          ],
          "fields": ""
        },
        "showThresholdLabels": false,
        "showThresholdMarkers": true,
        "text": {}
      },
      "pluginVersion": "8.0.0",
      "targets": [
        {
          "expr": "crawler_frontier_size",
          "refId": "A"
        }
      ],
      "title": "Frontier Size",
      "type": "gauge"
    },
    {
      "datasource": "Prometheus",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 10,
            "gradientMode": "none",
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": true,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "decbytes"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 8
      },
      "id": 4,
      "options": {
        "tooltip": {
          "mode": "single"
        },
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom"
        }
      },
      "pluginVersion": "8.0.0",
      "targets": [
        {
          "expr": "crawler_memory_usage_bytes",
          "legendFormat": "RSS Memory",
          "refId": "A"
        }
      ],
      "title": "Memory Usage",
      "type": "timeseries"
    },
    {
      "datasource": "Prometheus",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 10,
            "gradientMode": "none",
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": true,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 8
      },
      "id": 5,
      "options": {
        "tooltip": {
          "mode": "single"
        },
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom"
        }
      },
      "pluginVersion": "8.0.0",
      "targets": [
        {
          "expr": "crawler_active_workers",
          "legendFormat": "Active Workers",
          "refId": "A"
        }
      ],
      "title": "Active Workers",
      "type": "timeseries"
    },
    {
      "datasource": "Prometheus",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 10,
            "gradientMode": "none",
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": true,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "ms"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 16
      },
      "id": 6,
      "options": {
        "tooltip": {
          "mode": "single"
        },
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom"
        }
      },
      "pluginVersion": "8.0.0",
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(crawler_fetch_duration_seconds_bucket[5m])) by (le)) * 1000",
          "legendFormat": "95th percentile",
          "refId": "A"
        },
        {
          "expr": "histogram_quantile(0.50, sum(rate(crawler_fetch_duration_seconds_bucket[5m])) by (le)) * 1000",
          "legendFormat": "50th percentile",
          "refId": "B"
        }
      ],
      "title": "Fetch Duration Percentiles",
      "type": "timeseries"
    },
    {
      "datasource": "Prometheus",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "bars",
            "fillOpacity": 100,
            "gradientMode": "none",
            "hideFrom": {
              "tooltip": false,
              "viz": false,
              "legend": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 5,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": true,
            "stacking": {
              "group": "A",
              "mode": "normal"
            },
            "thresholdsStyle": {
              "mode": "off"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 16
      },
      "id": 7,
      "options": {
        "tooltip": {
          "mode": "multi"
        },
        "legend": {
          "calcs": [],
          "displayMode": "list",
          "placement": "bottom"
        }
      },
      "pluginVersion": "8.0.0",
      "targets": [
        {
          "expr": "sum(rate(crawler_errors_total[5m])) by (error_type)",
          "legendFormat": "{{error_type}}",
          "refId": "A"
        }
      ],
      "title": "Error Rate by Type",
      "type": "timeseries"
    }
  ],
  "refresh": "5s",
  "schemaVersion": 30,
  "style": "dark",
  "tags": ["crawler"],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-30m",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Web Crawler Dashboard",
  "uid": "crawler-dashboard",
  "version": 0
}
```

Now let's update the README.md to include the monitoring setup instructions:

```markdown
## Running Tests

The project uses `pytest` for testing. To run the tests:

1.  Ensure you have activated your virtual environment and installed dependencies (including `pytest` and `pytest-asyncio` from `requirements.txt`).
2.  Navigate to the `crawler/` directory (the root of the crawler project where `tests/` is located).
3.  Run pytest:
    ```bash
    pytest
    ```
    Or, for more verbose output:
    ```bash
    pytest -v
    ```

## Monitoring with Prometheus and Grafana

The crawler includes built-in metrics collection using Prometheus, with visualization through Grafana dashboards.

### Quick Start

1. **Install Docker and Docker Compose** (if not already installed)

2. **Start the monitoring stack**:
   ```bash
   cd crawler
   docker-compose up -d
   ```
   This starts Prometheus (port 9090) and Grafana (port 3000).

3. **Run the crawler** - it will automatically expose metrics on port 8001:
   ```bash
   python main.py --seed-file seeds.txt --email your@email.com
   ```

4. **Access Grafana**:
   - Open http://localhost:3000 in your browser
   - Login with username: `admin`, password: `admin`
   - The crawler dashboard is pre-configured and will show real-time metrics

### Available Metrics

The crawler tracks the following metrics:

- **Crawl Performance**:
  - Pages crawled per second
  - Total pages crawled
  - URLs added to frontier
  - Frontier size

- **Resource Usage**:
  - Memory usage (RSS)
  - Open file descriptors
  - Active worker threads
  - Database connection pool status

- **Performance Metrics**:
  - URL fetch duration (percentiles)
  - Database connection acquisition time
  - Database query execution time

- **Error Tracking**:
  - Errors by type (fetch errors, HTTP errors, etc.)

### Stopping the Monitoring Stack

```bash
docker-compose down
```

To also remove the stored metrics data:
```bash
docker-compose down -v
```

## Progress Inspection
```

```markdown
### 13.2. Database Abstraction

The crawler uses a database abstraction layer that:
- Provides async/await interface for both backends
- Handles connection pooling appropriately for each database
- Translates queries when needed (most SQL is compatible)
- Allows easy switching between backends for testing vs. production 

## 14. Monitoring and Metrics Collection

The crawler includes integrated monitoring capabilities using Prometheus for metrics collection and Grafana for visualization.

### 14.1. Metrics Architecture

*   **Metrics Module (`metrics.py`):**
    *   Uses `prometheus_client` library to expose metrics
    *   Runs an HTTP server on port 8001 for Prometheus to scrape
    *   Provides counters, gauges, and histograms for comprehensive monitoring

*   **Integration with Orchestrator:**
    *   Metrics are updated throughout the crawl lifecycle
    *   Minimal performance overhead with asynchronous updates
    *   Real-time visibility into crawler performance

### 14.2. Available Metrics

*   **Counters (monotonically increasing):**
    *   `crawler_pages_crawled_total`: Total successful page fetches
    *   `crawler_urls_added_total`: Total URLs added to frontier
    *   `crawler_errors_total`: Errors by type (fetch_error, HTTP status codes)

*   **Gauges (point-in-time values):**
    *   `crawler_pages_per_second`: Current crawl rate
    *   `crawler_frontier_size`: Current frontier size
    *   `crawler_active_workers`: Number of active worker tasks
    *   `crawler_memory_usage_bytes`: RSS memory usage
    *   `crawler_open_fds`: Open file descriptors
    *   `crawler_db_pool_available`: Available database connections

*   **Histograms (distributions):**
    *   `crawler_fetch_duration_seconds`: URL fetch time distribution
    *   `crawler_db_connection_acquire_seconds`: Database connection acquisition time
    *   `crawler_db_query_duration_seconds`: Database query execution time by query type

### 14.3. Monitoring Stack

*   **Docker Compose Setup:**
    *   Prometheus for metrics storage and querying
    *   Grafana for visualization with pre-configured dashboard
    *   Zero-configuration deployment

*   **Grafana Dashboard Features:**
    *   Real-time crawl rate visualization
    *   Resource usage monitoring
    *   Performance percentiles (P50, P95)
    *   Error rate tracking by type
    *   Automatic 5-second refresh

### 14.4. Benefits

*   **Performance Optimization:** Identify bottlenecks in real-time
*   **Resource Management:** Monitor memory and connection usage
*   **Error Detection:** Quickly spot and diagnose issues
*   **Historical Analysis:** Compare performance across runs
*   **Capacity Planning:** Understand resource requirements at scale
```

Let's also update the .gitignore to exclude Docker volumes:

```ignore
# Crawler specific
crawler_data/
*.db
*.db-journal
top-1M-domains.txt

# Docker and monitoring
docker-compose.override.yml
monitoring/grafana/data/
monitoring/prometheus/data/

# Pytest cache
.pytest_cache/
```

## Summary

I've successfully set up a comprehensive monitoring solution for your web crawler using Prometheus and Grafana! Here's what was implemented:

### ðŸš€ What's New

1. **Metrics Collection Module** (`crawler_module/metrics.py`):
   - Exposes metrics via HTTP endpoint on port 8001
   - Tracks counters, gauges, and histograms for all important crawler metrics
   - Minimal performance overhead

2. **Integrated Metrics in Orchestrator**:
   - Tracks page crawl rates, errors, fetch durations
   - Monitors resource usage (memory, file descriptors)
   - Records database performance metrics

3. **Docker Compose Setup**:
   - One-command deployment: `docker-compose up -d`
   - Prometheus configured to scrape crawler metrics
   - Grafana with auto-provisioned datasource

4. **Pre-configured Grafana Dashboard**:
   - Real-time visualization of crawl rate
   - Resource monitoring (memory, workers, frontier size)
   - Performance percentiles for fetch and DB operations
   - Error tracking by type

### ðŸ“Š How to Use

1. **Install dependencies**:
   ```bash
   pip install -r requirements.txt  # Now includes prometheus_client
   ```

2. **Start monitoring stack**:
   ```bash
   cd crawler
   docker-compose up -d
   ```

3. **Run your crawler** - metrics are automatically exposed:
   ```bash
   python main.py --seed-file seeds.txt --email your@email.com
   ```

4. **View metrics**:
   - Grafana: http://localhost:3000 (admin/admin)
   - Prometheus: http://localhost:9090
   - Raw metrics: http://localhost:8001/metrics

### ðŸŽ¯ Key Benefits

- **Real-time visibility** - No more parsing logs!
- **Historical data** - Track performance over time
- **Easy troubleshooting** - Spot bottlenecks instantly
- **Production-ready** - Same stack used by major tech companies
- **Simple maintenance** - All configuration is version-controlled

The setup is intentionally simple and follows best practices. You can now monitor your crawler's performance in real-time, correlate different metrics, and apply aggregations like smoothing and averaging directly in Grafana!

```shellscript
   pip install -r requirements.txt  # Now includes prometheus_client
```

```shellscript
   cd crawler
   docker-compose up -d
```

```shellscript
   python main.py --seed-file seeds.txt --email your@email.com
```

