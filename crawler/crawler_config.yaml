# Crawler Configuration - Pod-Based Architecture
# This file configures a 16-pod crawler setup for large-scale crawling

# Pod configuration - each pod gets its own Redis instance
pods:
  - redis_url: "redis://localhost:6379"
  - redis_url: "redis://localhost:6380"
  - redis_url: "redis://localhost:6381"
  - redis_url: "redis://localhost:6382"
  - redis_url: "redis://localhost:6383"
  - redis_url: "redis://localhost:6384"
  - redis_url: "redis://localhost:6385"
  - redis_url: "redis://localhost:6386"
  - redis_url: "redis://localhost:6387"
  - redis_url: "redis://localhost:6388"
  - redis_url: "redis://localhost:6389"
  - redis_url: "redis://localhost:6390"
  - redis_url: "redis://localhost:6391"
  - redis_url: "redis://localhost:6392"
  - redis_url: "redis://localhost:6393"
  - redis_url: "redis://localhost:6394"

# Storage configuration - shard content across multiple drives
data_dirs:
  - "/mnt/ssd1/crawler_data"
  - "/mnt/ssd2/crawler_data"
  - "/mnt/ssd3/crawler_data"
  - "/mnt/ssd4/crawler_data"

# Logging configuration
log_dir: "/var/log/crawler"
log_level: "INFO"

# Process configuration (per pod)
fetchers_per_pod: 6      # 96 total fetcher processes with 16 pods
parsers_per_pod: 2       # 32 total parser processes
fetcher_workers: 200     # Async workers per fetcher process
parser_workers: 50       # Async workers per parser process

# CPU affinity settings
enable_cpu_affinity: true
cores_per_pod: 12        # 192 total cores / 16 pods = 12

# Redis configuration (applied to all pods)
redis_db: 0
redis_password: null     # Set if using Redis AUTH
redis_socket_timeout: 30
redis_socket_connect_timeout: 10
redis_socket_keepalive: true
redis_max_connections: 1000  # Per Redis instance

# Crawler behavior settings
politeness_delay_seconds: 70
robots_cache_ttl_seconds: 86400  # 24 hours
http_timeout_seconds: 30
http_max_retries: 2
user_agent_template: "ExperimentalCrawler/1.0 ({email})"

# Content processing
max_content_length: 10485760  # 10MB
extract_text: true
store_raw_html: false

# Frontier management
bloom_filter_capacity: 10000000000  # 10 billion
bloom_filter_error_rate: 0.001
frontier_batch_size: 1000

# Performance tuning
parse_queue_soft_limit: 20000  # Per pod
parse_queue_hard_limit: 80000  # Per pod

# Global coordination
global_coordination_redis_pod: 0  # Pod 0 handles global state
global_metrics_update_interval: 10  # seconds

# Monitoring
prometheus_port: 8001
enable_prometheus: true

# Resource limits (optional, for containerized deployment)
fetcher_memory_limit: "2G"    # Per fetcher process
parser_memory_limit: "4G"     # Per parser process
orchestrator_memory_limit: "2G"

# Test mode settings (for development)
test_mode:
  enabled: false
  num_pods: 4
  fetchers_per_pod: 2
  parsers_per_pod: 1
  data_dirs:
    - "./test_data/ssd1"
    - "./test_data/ssd2" 